{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7204, 0.1274],\n",
      "        [0.0348, 0.3540]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2254, 0.8912, 0.3584],\n",
      "        [0.0361, 0.3714, 0.7159]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "2\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor = torch.rand(3, 4)\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[36., 25., 36., 36.],\n",
      "        [36., 25., 36., 36.],\n",
      "        [36., 25., 36., 36.],\n",
      "        [36., 25., 36., 36.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[36., 25., 36., 36.],\n",
      "        [36., 25., 36., 36.],\n",
      "        [36., 25., 36., 36.],\n",
      "        [36., 25., 36., 36.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)\n",
    "\n",
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False])\n",
      "tensor([False, False])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([2., 3.], requires_grad=True)\n",
    "x2 = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = (3*x1 - 2*x2 - 2)**2\n",
    "\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)\n",
    "\n",
    "print(3*x1**2 == x1.grad)\n",
    "print(-2*x2 == x2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        # 784 is the input dimension, and 68 is the output dimenstion of the first hidden layer\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4= nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        # apply the first layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "for p in params:\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0038,  0.0129,  0.0014,  0.0844, -0.0474, -0.1092,  0.1090,  0.0761,\n",
      "          0.0315, -0.1299]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 784)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "training_data = datasets.MNIST(\n",
    "root=\"data\",\n",
    "train=True,\n",
    "download=True,\n",
    "transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "root=\"data\",\n",
    "train=False,\n",
    "download=True,\n",
    "transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(\"digit:\" + str(label))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n",
      "1\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available\")\n",
    "\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m iteration_loss \u001b[38;5;241m=\u001b[39m loss(outputs, labels)\n\u001b[0;32m     14\u001b[0m iteration_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# apply the first layer with relu activation\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(5): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.flatten(inputs,1))\n",
    "        iteration_loss = loss(outputs, labels)\n",
    "        iteration_loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += iteration_loss.item()\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './my_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(torch.flatten(images,1))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.073\n",
      "[1,  4000] loss: 0.071\n",
      "[1,  6000] loss: 0.079\n",
      "[1,  8000] loss: 0.068\n",
      "[1, 10000] loss: 0.065\n",
      "[1, 12000] loss: 0.070\n",
      "[1, 14000] loss: 0.081\n",
      "[2,  2000] loss: 0.055\n",
      "[2,  4000] loss: 0.069\n",
      "[2,  6000] loss: 0.075\n",
      "[2,  8000] loss: 0.070\n",
      "[2, 10000] loss: 0.062\n",
      "[2, 12000] loss: 0.078\n",
      "[2, 14000] loss: 0.072\n",
      "[3,  2000] loss: 0.055\n",
      "[3,  4000] loss: 0.065\n",
      "[3,  6000] loss: 0.051\n",
      "[3,  8000] loss: 0.069\n",
      "[3, 10000] loss: 0.068\n",
      "[3, 12000] loss: 0.062\n",
      "[3, 14000] loss: 0.068\n",
      "[4,  2000] loss: 0.048\n",
      "[4,  4000] loss: 0.054\n",
      "[4,  6000] loss: 0.060\n",
      "[4,  8000] loss: 0.071\n",
      "[4, 10000] loss: 0.066\n",
      "[4, 12000] loss: 0.055\n",
      "[4, 14000] loss: 0.054\n",
      "[5,  2000] loss: 0.048\n",
      "[5,  4000] loss: 0.053\n",
      "[5,  6000] loss: 0.062\n",
      "[5,  8000] loss: 0.063\n",
      "[5, 10000] loss: 0.071\n",
      "[5, 12000] loss: 0.062\n",
      "[5, 14000] loss: 0.054\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(5): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.flatten(inputs,1))\n",
    "        iteration_loss = loss(outputs, labels)\n",
    "        iteration_loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += iteration_loss.item()\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
